{"cells":[{"cell_type":"markdown","id":"Dv8absVKufcA","metadata":{"id":"Dv8absVKufcA"},"source":["# Semantic Segmentation with Deep Learning: Training and Testing on Colab\n","\n","Insert the following Javascript snippet into your browser console so that your Colab runtime won't time out. Open developer-settings (in your web-browser) with Ctrl+Shift+I then click on console tab and type this on the console prompt. (for mac press Option+Command+I)\n","```Javascript\n","function ClickConnect(){\n","    console.log(\"Clicked on connect button\"); \n","    document.querySelector(\"colab-connect-button\").click()\n","}\n","setInterval(ClickConnect,60000)\n","```"]},{"cell_type":"markdown","id":"bdweXW5Xqd6R","metadata":{"id":"bdweXW5Xqd6R"},"source":["Zip up your code locally with `python zip_for_colab.py`, and upload your `cv_proj5.zip` file. Hit refresh, then run the following:"]},{"cell_type":"code","execution_count":null,"id":"ah8PNwYTqM1G","metadata":{"id":"ah8PNwYTqM1G","scrolled":true},"outputs":[],"source":["!unzip cv_proj5_colab.zip"]},{"cell_type":"markdown","id":"0pf627lnqsTo","metadata":{"id":"0pf627lnqsTo"},"source":["Install the `proj6_code` module locally:"]},{"cell_type":"code","execution_count":null,"id":"sEkEfbqNqxa4","metadata":{"id":"sEkEfbqNqxa4"},"outputs":[],"source":["!ls"]},{"cell_type":"markdown","id":"sensitive-franchise","metadata":{"id":"sensitive-franchise"},"source":["Download ImageNet-pretrained ResNet-50:\n"]},{"cell_type":"code","execution_count":null,"id":"bound-explosion","metadata":{"id":"bound-explosion"},"outputs":[],"source":["!wget -O \"resnet50_v2.pth\" --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w5pRmLJXvmQQA5PtCbHhZc_uC4o0YbmA'\n","!mkdir initmodel && mv resnet50_v2.pth initmodel/"]},{"cell_type":"code","execution_count":null,"id":"yZDeFtlyuXNz","metadata":{"id":"yZDeFtlyuXNz"},"outputs":[],"source":["# The ImageNet-pretrained ResNet-50 weights should be 99 MB\n","!ls -ltrh initmodel"]},{"cell_type":"markdown","id":"7wzfFzyHupog","metadata":{"id":"7wzfFzyHupog"},"source":["Download the Camvid dataset images. It's 700 MB, but it should only take 30 sec."]},{"cell_type":"code","execution_count":null,"id":"intellectual-delaware","metadata":{"id":"intellectual-delaware"},"outputs":[],"source":["!chmod +rwx download_dataset.sh\n","!sed -i -e 's/\\r$//' download_dataset.sh\n","!./download_dataset.sh Camvid"]},{"cell_type":"code","execution_count":null,"id":"PGBUoTc9Aj0t","metadata":{"id":"PGBUoTc9Aj0t"},"outputs":[],"source":["!ls\n","!cd Camvid && unzip camvid_semseg11.zip && cd .."]},{"cell_type":"markdown","id":"AC_-gfRptGgF","metadata":{"id":"AC_-gfRptGgF"},"source":["We'll now set some default hyperparameters for training. Choose the number of epochs you'd like to train for (for PSPNet, it will take ~30 min for 50 epochs, or ~70 min for 100 epochs)."]},{"cell_type":"code","execution_count":null,"id":"absent-major","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"absent-major","outputId":"a9d84bd5-d501-4b15-c3ff-2a2311b94ee4","executionInfo":{"status":"ok","timestamp":1670454303076,"user_tz":300,"elapsed":26,"user":{"displayName":"RS Z","userId":"16888852220905981586"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.8.15\n"]}],"source":["!python --version\n","from types import SimpleNamespace\n","\n","args = SimpleNamespace(\n","    **{\n","        # DATA\n","        \"names_path\": \"./dataset_lists/camvid-11/camvid-11_names.txt\",\n","        \"data_root\": \"./Camvid/\",\n","        \"train_list\": \"./src/dataset_lists/camvid-11/list/train.txt\",  \n","        \"val_list\": \"./src/dataset_lists/camvid-11/list/val.txt\",\n","        \"classes\": 11,\n","        # TRAIN\n","        \"arch\": \"PSPNet\", #  \"SimpleSegmentationNet\", # \n","        \"save_path\": \"\",\n","        \"epochs\": 5,\n","        \"zoom_factor\": 8,\n","        \"use_ppm\": True,\n","        \"aux_weight\": 0.4,\n","        \"aux_loss\": True,\n","        \"layers\": 50,\n","        \"workers\": 2,\n","        \"batch_size\": 32,\n","        \"batch_size_val\": 32,\n","        \"data_aug\": True,\n","        \"short_size\": 240,\n","        \"train_h\": 201,\n","        \"train_w\": 201,\n","        \"init_weight\": \"./initmodel/resnet50_v2.pth\",\n","        \"scale_min\": 0.5,  # minimum random scale\n","        \"scale_max\": 2.0,  # maximum random scale\n","        \"rotate_min\": -10,  # minimum random rotate\n","        \"rotate_max\": 10,  # maximum random rotate\n","        \"ignore_label\": 255,\n","        \"base_lr\": 0.01,\n","        \"start_epoch\": 0,\n","        \"power\": 0.9,\n","        \"momentum\": 0.9,\n","        \"weight_decay\": 0.0001,\n","        \"manual_seed\": 0,\n","        \"print_freq\": 10,\n","        \"save_freq\": 1,\n","        \"evaluate\": True,  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend\n","        \"multiprocessing_distributed\": False,\n","        # INFERENCE\n","        \"dataset\": \"camvid-11\",\n","        \"base_size\": 240,\n","        \"test_h\": 201,\n","        \"test_w\": 201,\n","        \"scales\": [1.0], # [0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n","        \"test_list\": \"./src/dataset_lists/camvid-11/list/val.txt\",\n","        \"vis_freq\": 10,\n","        \"pretrained\": True\n","    }\n",")\n","\n","args.save_path = f\"exp/camvid/{args.arch}/model\""]},{"cell_type":"code","execution_count":null,"id":"increased-blade","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"increased-blade","outputId":"20faf4cc-dc80-4f73-8f1e-0438034f73c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["namespace(arch='PSPNet', aux_loss=True, aux_weight=0.4, base_lr=0.01, base_size=240, batch_size=32, batch_size_val=32, classes=11, data_aug=True, data_root='./Camvid/', dataset='camvid-11', epochs=5, evaluate=True, ignore_label=255, init_weight='./initmodel/resnet50_v2.pth', layers=50, manual_seed=0, momentum=0.9, multiprocessing_distributed=False, names_path='./dataset_lists/camvid-11/camvid-11_names.txt', power=0.9, pretrained=True, print_freq=10, rotate_max=10, rotate_min=-10, save_freq=1, save_path='exp/camvid/PSPNet/model', scale_max=2.0, scale_min=0.5, scales=[1.0], short_size=240, start_epoch=0, test_h=201, test_list='./src/dataset_lists/camvid-11/list/val.txt', test_w=201, train_h=201, train_list='./src/dataset_lists/camvid-11/list/train.txt', train_w=201, use_ppm=True, val_list='./src/dataset_lists/camvid-11/list/val.txt', vis_freq=10, weight_decay=0.0001, workers=2, zoom_factor=8)\n","namespace(arch='PSPNet', aux_loss=True, aux_weight=0.4, base_lr=0.01, base_size=240, batch_size=32, batch_size_val=32, classes=11, data_aug=True, data_root='./Camvid/', dataset='camvid-11', epochs=5, evaluate=True, ignore_label=255, init_weight='./initmodel/resnet50_v2.pth', layers=50, manual_seed=0, momentum=0.9, multiprocessing_distributed=False, names_path='./dataset_lists/camvid-11/camvid-11_names.txt', power=0.9, pretrained=True, print_freq=10, rotate_max=10, rotate_min=-10, save_freq=1, save_path='exp/camvid/PSPNet/model', scale_max=2.0, scale_min=0.5, scales=[1.0], short_size=240, start_epoch=0, test_h=201, test_list='./src/dataset_lists/camvid-11/list/val.txt', test_w=201, train_h=201, train_list='./src/dataset_lists/camvid-11/list/train.txt', train_w=201, use_ppm=True, val_list='./src/dataset_lists/camvid-11/list/val.txt', vis_freq=10, weight_decay=0.0001, workers=2, zoom_factor=8)\n","[2022-12-07 23:05:04,528 INFO trainer.py line 59 411] namespace(arch='PSPNet', aux_loss=True, aux_weight=0.4, base_lr=0.01, base_size=240, batch_size=32, batch_size_val=32, classes=11, data_aug=True, data_root='./Camvid/', dataset='camvid-11', epochs=5, evaluate=True, ignore_label=255, init_weight='./initmodel/resnet50_v2.pth', layers=50, manual_seed=0, momentum=0.9, multiprocessing_distributed=False, names_path='./dataset_lists/camvid-11/camvid-11_names.txt', power=0.9, pretrained=True, print_freq=10, rotate_max=10, rotate_min=-10, save_freq=1, save_path='exp/camvid/PSPNet/model', scale_max=2.0, scale_min=0.5, scales=[1.0], short_size=240, start_epoch=0, test_h=201, test_list='./src/dataset_lists/camvid-11/list/val.txt', test_w=201, train_h=201, train_list='./src/dataset_lists/camvid-11/list/train.txt', train_w=201, use_ppm=True, val_list='./src/dataset_lists/camvid-11/list/val.txt', vis_freq=10, weight_decay=0.0001, workers=2, zoom_factor=8)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:main-logger:namespace(arch='PSPNet', aux_loss=True, aux_weight=0.4, base_lr=0.01, base_size=240, batch_size=32, batch_size_val=32, classes=11, data_aug=True, data_root='./Camvid/', dataset='camvid-11', epochs=5, evaluate=True, ignore_label=255, init_weight='./initmodel/resnet50_v2.pth', layers=50, manual_seed=0, momentum=0.9, multiprocessing_distributed=False, names_path='./dataset_lists/camvid-11/camvid-11_names.txt', power=0.9, pretrained=True, print_freq=10, rotate_max=10, rotate_min=-10, save_freq=1, save_path='exp/camvid/PSPNet/model', scale_max=2.0, scale_min=0.5, scales=[1.0], short_size=240, start_epoch=0, test_h=201, test_list='./src/dataset_lists/camvid-11/list/val.txt', test_w=201, train_h=201, train_list='./src/dataset_lists/camvid-11/list/train.txt', train_w=201, use_ppm=True, val_list='./src/dataset_lists/camvid-11/list/val.txt', vis_freq=10, weight_decay=0.0001, workers=2, zoom_factor=8)\n"]},{"output_type":"stream","name":"stdout","text":["[2022-12-07 23:05:04,532 INFO trainer.py line 60 411] => creating model ...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:main-logger:=> creating model ...\n"]},{"output_type":"stream","name":"stdout","text":["[2022-12-07 23:05:04,536 INFO trainer.py line 61 411] Classes: 11\n"]},{"output_type":"stream","name":"stderr","text":["INFO:main-logger:Classes: 11\n"]},{"output_type":"stream","name":"stdout","text":["List of (image,label) pairs train list generated!\n","List of (image,label) pairs val list generated!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3734: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"]}],"source":["import os\n","\n","import torch\n","\n","os.makedirs(args.save_path, exist_ok=True)\n","from vision.trainer import main_worker\n","print(args)\n","main_worker(args, torch.cuda.is_available())"]},{"cell_type":"markdown","id":"7or_wjTqvX6H","metadata":{"id":"7or_wjTqvX6H"},"source":["We'll now create full-resolution predictions for the full val set, and compute mIoU against the ground truth."]},{"cell_type":"code","execution_count":null,"id":"worst-vegetation","metadata":{"id":"worst-vegetation"},"outputs":[],"source":["from vision.test import test_model\n","args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n","test_model(args)"]},{"cell_type":"markdown","id":"ETWCIkf1vfCP","metadata":{"id":"ETWCIkf1vfCP"},"source":["**Important**: Record the mIoU listed in the output above, and the IoU per each class. You can find the results later in `train_epoch_{args.epochs}/camvid-11/720/results.txt`.\n","\n","Now, let's take a look at what our results look like. We'll make a 2x3 image grid with the following structure:\n","\n","|RGB Image | Blended RGB and Ground Truth | Ground Truth \n","|:-: | :-: | :-:\n","| RGB Image | Blended RGB and Prediction | Prediction"]},{"cell_type":"code","execution_count":null,"id":"cDpIrDQvvBq5","metadata":{"id":"cDpIrDQvvBq5"},"outputs":[],"source":["import imageio\n","import matplotlib.pyplot as plt\n","\n","rgb_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/rgb_mask_predictions\"\n","\n","def show_image_grid(rgb_predictions_dir: str, img_fname: str) -> None:\n","  img_grid = imageio.imread(f'{rgb_predictions_dir}/{img_fname}')\n","  plt.figure(figsize=(15,7))\n","  plt.imshow(img_grid)\n","  plt.show()\n","\n","show_image_grid(rgb_predictions_dir, \"0016E5_07977.jpg\")"]},{"cell_type":"markdown","id":"JOxOOpJ-wDHa","metadata":{"id":"JOxOOpJ-wDHa"},"source":["We'll look at more examples:"]},{"cell_type":"code","execution_count":null,"id":"wJo0THuZvDkU","metadata":{"id":"wJo0THuZvDkU"},"outputs":[],"source":["show_image_grid(rgb_predictions_dir, \"0016E5_07997.jpg\")\n","show_image_grid(rgb_predictions_dir, \"0016E5_08017.jpg\")\n","show_image_grid(rgb_predictions_dir, \"0016E5_08037.jpg\")\n","show_image_grid(rgb_predictions_dir, \"0016E5_08057.jpg\")\n","show_image_grid(rgb_predictions_dir, \"0016E5_08077.jpg\")\n","show_image_grid(rgb_predictions_dir, \"0016E5_08097.jpg\")\n","show_image_grid(rgb_predictions_dir, \"0016E5_08117.jpg\")\n","show_image_grid(rgb_predictions_dir, \"0016E5_08137.jpg\")\n","show_image_grid(rgb_predictions_dir, \"0016E5_08157.jpg\")"]},{"cell_type":"markdown","id":"VFCSB5B23t19","metadata":{"id":"VFCSB5B23t19"},"source":["Now, zip up your predictions on the test set for your best model, **download them locally to your machine**, and submit these to Gradescope:"]},{"cell_type":"code","execution_count":null,"id":"VbYbqcNn3eS2","metadata":{"id":"VbYbqcNn3eS2"},"outputs":[],"source":["grayscale_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/gray\"\n","!ls -ltrh $grayscale_predictions_dir\n","!zip -r grayscale_predictions.zip $grayscale_predictions_dir\n","!ls -ltrh grayscale_predictions.zip"]},{"cell_type":"markdown","id":"e62e5d36","metadata":{"id":"e62e5d36"},"source":["In this section you will load the model trained on the Camvid-11 dataset and train it on the Kitti Road Segmentation dataset."]},{"cell_type":"code","execution_count":null,"id":"foAbZe_L38S9","metadata":{"id":"foAbZe_L38S9"},"outputs":[],"source":["args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n","args.data_root = \"./kitti\"\n","args.classes = 2\n","args.save_path = f\"exp/kitti/{args.arch}/model\"\n","args.batch_size = 32\n","args.batch_size_val = 1\n","args.dataset = \"kitti\"\n","args.evaluate = False\n","args.epochs = 20\n","\n","import os\n","\n","import torch\n","os.makedirs(args.save_path, exist_ok=True)\n","print(args)"]},{"cell_type":"code","execution_count":null,"id":"9fa2cc0f","metadata":{"id":"9fa2cc0f"},"outputs":[],"source":["args.base_lr = 0.01\n","args.momentum = 0.9\n","args.weight_decay = 0.0001"]},{"cell_type":"code","execution_count":null,"id":"3a05dfab","metadata":{"id":"3a05dfab"},"outputs":[],"source":["from vision.trainer import transfer_train\n","transfer_train(args, torch.cuda.is_available())"]},{"cell_type":"markdown","id":"eb177e31","metadata":{"id":"eb177e31"},"source":["## Don't forget to download the grayscale_predictions.zip and exp folder!"]},{"cell_type":"markdown","id":"7062ccc1","metadata":{"id":"7062ccc1"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"gpuClass":"premium"},"nbformat":4,"nbformat_minor":5}